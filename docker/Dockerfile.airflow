FROM apache/airflow:2.2.4-python3.7

# Install Poetry for better python dependency management and packaging
RUN pip install poetry

ENV AUDIO_CLASSIFIER_PKG=/tmp/custom-python-pkg/ 

# Copy the python package to the container
COPY ./audio_classifier/ ${AUDIO_CLASSIFIER_PKG}

# User root pour donner les droits aux user Airflow d'installer et modifier le pkg Audiclassifier
USER root
RUN cd ${AUDIO_CLASSIFIER_PKG} && chmod -R 777 .
USER airflow

# # Note we are using this because we are using standard python operators in airflow to run dags
# In future we could isolate this dependencies using docker operators in airflow
RUN cd ${AUDIO_CLASSIFIER_PKG} && poetry install --no-root --no-interaction \
 && rm -rf ~/.cache/pypoetry/{cache,artifacts}

# Since we dont have a internal PyPi repo installing locally
RUN cd ${AUDIO_CLASSIFIER_PKG} && poetry build && python -m pip install $(find ./dist -name '*.tar.gz') \
  && rm -rf dist

# Cleanup package source code
RUN rm -r ${AUDIO_CLASSIFIER_PKG}*

ENV MY_LOCAL_ASSETS=/opt/airflow/local-assets/

# Copy python scripts and configurations
COPY scripts/ml/ ${MY_LOCAL_ASSETS}

# Copy test raw input audio data since for this demo we dont have any cloud storage option
COPY data/ ${MY_LOCAL_ASSETS}/raw_input_data/

# Install MLFlow for remote tracking since we don't want to add this dependency to the audio_classifier
RUN pip install mlflow


# Définir les permissions sur les répertoires en mode root
USER root

RUN cd ${MY_LOCAL_ASSETS} && chmod -R 777 .

USER airflow

